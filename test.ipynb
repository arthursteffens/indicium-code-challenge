{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy\n",
    "from sqlalchemy import create_engine, text\n",
    "import yaml\n",
    "import logging\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"docker-compose.yml\", \"r\") as file:\n",
    "    yml = yaml.safe_load(file)\n",
    "\n",
    "class DBCred():\n",
    "    def __init__(self, service) -> None:\n",
    "        try:\n",
    "            db =  yml[\"services\"][service]\n",
    "            env = db[\"environment\"]\n",
    "\n",
    "            if service == \"pg_db\":\n",
    "                self.db_prefix = \"POSTGRES\"\n",
    "                self.eng_driver = \"postgresql+psycopg2\"\n",
    "                self.db_name = env[f\"{self.db_prefix}_DB\"]\n",
    "                self.user=env[f\"{self.db_prefix}_USER\"]\n",
    "                self.passwd=env[f\"{self.db_prefix}_PASSWORD\"]\n",
    "                self.port=yml[\"services\"][service][\"ports\"][0].split(\":\")[0]\n",
    "                self.host=\"localhost\"\n",
    "            \n",
    "            if service == \"mysql_db\":\n",
    "                self.db_prefix = \"MYSQL\"\n",
    "                self.eng_driver = \"mysql+pymysql\"\n",
    "                self.db_name = env[f\"{self.db_prefix}_DATABASE\"]\n",
    "                self.user=env[f\"{self.db_prefix}_USER\"]\n",
    "                self.passwd=env[f\"{self.db_prefix}_PASSWORD\"]\n",
    "                self.port=yml[\"services\"][service][\"ports\"][0].split(\":\")[0]\n",
    "                self.host=\"localhost\"\n",
    "                \n",
    "            self.conn_str = f\"{self.eng_driver}://{self.user}:{self.passwd}@{self.host}:{self.port}/{self.db_name}\"\n",
    "\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Invalid docker-compose.yml: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_db_cred = DBCred(\"pg_db\")\n",
    "dest_db_cred = DBCred(\"mysql_db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class Database():\n",
    "#     def __init__(self, db_cred):\n",
    "#         self.prefix = db_cred.db_prefix\n",
    "#         self.name = db_cred.db_name\n",
    "#         self.conn_str = db_cred.conn_str\n",
    "#         self.conn = self._connect()\n",
    "#         self.cur = self.conn.cursor()\n",
    "\n",
    "#     def _connect(self):\n",
    "#         try:\n",
    "#             if self.prefix == \"POSTGRES\":\n",
    "#                 return psycopg2.connect(self.credentials_dsn)\n",
    "#             elif self.prefix == \"MYSQL\":\n",
    "#                 return pymysql.connect(host='localhost', user='user', password='userpass', port=3306, db=f\"{self.name}\")\n",
    "#         except Exception as e:\n",
    "#             logging.error(f\"Error connecting to database: {e}\")\n",
    "\n",
    "#     def get_table_names(self, sql):\n",
    "#         \"\"\"\n",
    "#             Retrieve name of tables from source DB\n",
    "#             return 'list' : 'table_names'\n",
    "#         \"\"\"\n",
    "#         try:\n",
    "#             self.cur.execute(sql)\n",
    "#             results = self.cur.fetchall()\n",
    "#             table_names = [table_name[0] for table_name in results]\n",
    "#             logging.info(f\"Got {len(table_names)} tables: {table_names} \\n\")\n",
    "#             return table_names\n",
    "#         except Exception as e:\n",
    "#             logging.error(f\"Error retrieving table names, check database status or SQL syntax: \\n{e}\")\n",
    "\n",
    "#     def extract_db(self, table_names, user_date):\n",
    "#         \"\"\"\n",
    "#             Extract data from source DB.\n",
    "#             Write each table into csv files.\n",
    "#         \"\"\"\n",
    "#         try:\n",
    "#             for table in table_names:\n",
    "#                 path = f\"./data/postgres/{table}/{user_date}/{table}.csv\"\n",
    "#                 self.cur.execute(f\"SELECT * FROM {table};\")\n",
    "#                 columns = [col[0] for col in self.cur.description]\n",
    "#                 result = self.cur.fetchall()\n",
    "#                 df = pd.DataFrame(columns=columns, data=result)\n",
    "#                 final_df = df.astype(object).where(pd.notnull(df), 'NULL')\n",
    "#                 final_df.to_csv(path, index=False, sep=',', encoding='utf-8')\n",
    "#             logging.info(\"Tables extracted.\\n\")\n",
    "#         except Exception as e:\n",
    "#             logging.error(f\"Error while extracting or saving data from Postgres DB: {e}\")\n",
    "\n",
    "\n",
    "#     def insert_into_db(self, source, table, user_date):\n",
    "#         \"\"\"\n",
    "#             Insert data into destination DB.\n",
    "#             return 'bool' : success\n",
    "#         \"\"\"\n",
    "#         success = False\n",
    "#         if source == \"postgres\":\n",
    "#             path = f\"./data/{source}/{table}/{user_date}/{table}.csv\"\n",
    "#         elif source == \"csv\":\n",
    "#             path = f\"./data/{source}/{user_date}/{table}.csv\"\n",
    "        \n",
    "#         try:\n",
    "#             df = pd.read_csv(path, encoding=\"utf-8\")\n",
    "#             df.replace(to_replace=np.nan, value='NULL', inplace=True)\n",
    "                \n",
    "#             self.cursor.execute(\"SET FOREIGN_KEY_CHECKS=0;\")\n",
    "#             self.cursor.execute(f\"DELETE FROM {table};\")\n",
    "            \n",
    "#             for i in range(len(df)):\n",
    "#                 row_tuple = tuple(df.to_records(index=False))\n",
    "                \n",
    "#                 sql = f'''\n",
    "#                     INSERT INTO {table} VALUES {row_tuple[i]};\n",
    "#                 '''\n",
    "\n",
    "#                 self.cursor.execute(sql)\n",
    "#             self.cursor.execute(\"SET FOREIGN_KEY_CHECKS=1;\")\n",
    "#             success = True\n",
    "#             return success\n",
    "#         except Exception as e:\n",
    "#             print(f\"Error loading data into destination database: {e}\")\n",
    "\n",
    "\n",
    "#     def final_query(self, user_date, sql):\n",
    "#         \"\"\"\n",
    "#             Execute final query on destination DB and write result into 'final_query.csv'\n",
    "#         \"\"\"\n",
    "#         path = f\"./data/track/{user_date}/final_query.csv\"\n",
    "#         self.cursor.execute(sql)\n",
    "#         cols = [col[0] for col in self.cursor.description]\n",
    "#         results = self.cursor.fetchall()\n",
    "#         df = pd.DataFrame(results, columns=cols)\n",
    "#         df.to_csv(path, index=False, sep=',', encoding='utf-8')\n",
    "\n",
    "\n",
    "#     def close_connection(self):\n",
    "#         \"\"\"Close the connection with the database.\"\"\"\n",
    "#         self.cur.close()\n",
    "#         self.conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Database():\n",
    "    def __init__(self, db_cred):\n",
    "        self.conn_str = db_cred.conn_str\n",
    "        self.engine = create_engine(self.conn_str)\n",
    "\n",
    "\n",
    "    def get_table_names(self, sql):\n",
    "        \"\"\"\n",
    "            Retrieve name of tables from source DB\n",
    "            return 'list' : 'table_names'\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with self.engine.connect() as connection:\n",
    "                results = connection.execute(text(sql))\n",
    "\n",
    "            table_names = [table_name[0] for table_name in results]\n",
    "            logging.info(f\"Got {len(table_names)} tables: {table_names} \\n\")\n",
    "            return table_names\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error retrieving table names, check database status or SQL syntax: \\n{e}\")\n",
    "\n",
    "    def extract_db(self, table_names, user_date):\n",
    "        \"\"\"\n",
    "            Extract data from source DB.\n",
    "            Write each table into csv files.\n",
    "        \"\"\"\n",
    "        try:\n",
    "            with self.engine.connect() as connection:\n",
    "                for table in table_names:\n",
    "                    path = f\"./data/postgres/{table}/{user_date}/{table}.csv\"\n",
    "                    result = connection.execute(text(f\"SELECT * FROM {table};\"))\n",
    "                    columns = result._metadata.keys\n",
    "                    df = pd.DataFrame(columns=columns, data=result)\n",
    "                    final_df = df.astype(object).where(pd.notnull(df), 'NULL')\n",
    "                    final_df.to_csv(path, index=False, sep=',', encoding='utf-8')\n",
    "            logging.info(\"Tables extracted.\\n\")\n",
    "        except Exception as e:\n",
    "            logging.error(f\"Error while extracting or saving data from Postgres DB: {e}\")\n",
    "\n",
    "\n",
    "    def insert_into_db(self, source, table, user_date):\n",
    "        \"\"\"\n",
    "            Insert data into destination DB.\n",
    "            return 'bool' : success\n",
    "        \"\"\"\n",
    "        success = False\n",
    "        if source == \"postgres\":\n",
    "            path = f\"./data/{source}/{table}/{user_date}/{table}.csv\"\n",
    "        elif source == \"csv\":\n",
    "            path = f\"./data/{source}/{user_date}/{table}.csv\"\n",
    "        \n",
    "        try:\n",
    "            df = pd.read_csv(path, encoding=\"utf-8\")\n",
    "            df.replace(to_replace=np.nan, value='NULL', inplace=True)\n",
    "\n",
    "\n",
    "            with self.engine.connect() as connection:\n",
    "                connection.execute(text(\"SET FOREIGN_KEY_CHECKS=0;\"))\n",
    "                \n",
    "                # db_conn = self.engine.connect()\n",
    "                df.to_sql(table, connection, if_exists=\"replace\", index=False)\n",
    "            #     connection.execute(text(f\"DELETE FROM {table};\"))\n",
    "                \n",
    "            #     for i in range(len(df)):\n",
    "            #         row_tuple = tuple(df.to_records(index=False))\n",
    "                    \n",
    "            #         sql = f\"\"\"\n",
    "            #             INSERT INTO {table} VALUES {row_tuple[i]};\n",
    "            #         \"\"\"\n",
    "\n",
    "            #         connection.execute(text(sql))\n",
    "                connection.execute(text(\"SET FOREIGN_KEY_CHECKS=1;\"))\n",
    "                connection.commit()\n",
    "            success = True\n",
    "            return success\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading data into destination database: {e}\")\n",
    "\n",
    "\n",
    "    def final_query(self, user_date, sql):\n",
    "        \"\"\"\n",
    "            Execute final query on destination DB and write result into 'final_query.csv'\n",
    "        \"\"\"\n",
    "        path = f\"./data/track/{user_date}/final_query.csv\"\n",
    "        self.cursor.execute(sql)\n",
    "        cols = [col[0] for col in self.cursor.description]\n",
    "        results = self.cursor.fetchall()\n",
    "        df = pd.DataFrame(results, columns=cols)\n",
    "        df.to_csv(path, index=False, sep=',', encoding='utf-8')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    # def close_connection(self):\n",
    "    #     \"\"\"Close the connection with the database.\"\"\"\n",
    "    #     self.cur.close()\n",
    "    #     self.conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_db = Database(source_db_cred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 455,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_db = Database(dest_db_cred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.constants import sql_PG_TABLE_NAMES_QUERY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "src_tables = source_db.get_table_names(sql_PG_TABLE_NAMES_QUERY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_date = \"2023-01-30\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 459,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Step 1 already executed for this date. Reprocessing it for the selected day (2023-01-30).\n",
      "./data/postgres/suppliers/2023-01-30 recreated.\n",
      "\n",
      "Step 1 already executed for this date. Reprocessing it for the selected day (2023-01-30).\n",
      "./data/postgres/employees/2023-01-30 recreated.\n",
      "\n",
      "Step 1 already executed for this date. Reprocessing it for the selected day (2023-01-30).\n",
      "./data/postgres/shippers/2023-01-30 recreated.\n",
      "\n",
      "Step 1 already executed for this date. Reprocessing it for the selected day (2023-01-30).\n",
      "./data/postgres/categories/2023-01-30 recreated.\n",
      "\n",
      "Step 1 already executed for this date. Reprocessing it for the selected day (2023-01-30).\n",
      "./data/postgres/employee_territories/2023-01-30 recreated.\n",
      "\n",
      "Step 1 already executed for this date. Reprocessing it for the selected day (2023-01-30).\n",
      "./data/postgres/region/2023-01-30 recreated.\n",
      "\n",
      "Step 1 already executed for this date. Reprocessing it for the selected day (2023-01-30).\n",
      "./data/postgres/customer_demographics/2023-01-30 recreated.\n",
      "\n",
      "Step 1 already executed for this date. Reprocessing it for the selected day (2023-01-30).\n",
      "./data/postgres/us_states/2023-01-30 recreated.\n",
      "\n",
      "Step 1 already executed for this date. Reprocessing it for the selected day (2023-01-30).\n",
      "./data/postgres/products/2023-01-30 recreated.\n",
      "\n",
      "Step 1 already executed for this date. Reprocessing it for the selected day (2023-01-30).\n",
      "./data/postgres/territories/2023-01-30 recreated.\n",
      "\n",
      "Step 1 already executed for this date. Reprocessing it for the selected day (2023-01-30).\n",
      "./data/postgres/customer_customer_demo/2023-01-30 recreated.\n",
      "\n",
      "Step 1 already executed for this date. Reprocessing it for the selected day (2023-01-30).\n",
      "./data/postgres/customers/2023-01-30 recreated.\n",
      "\n",
      "Step 1 already executed for this date. Reprocessing it for the selected day (2023-01-30).\n",
      "./data/postgres/orders/2023-01-30 recreated.\n",
      "\n",
      "\n",
      "\n",
      "Step 1 already executed for this date. Reprocessing it for the selected day (2023-01-30).\n",
      "./data/csv/2023-01-30 recreated.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from scripts.functions import create_db_path, create_csv_path, extract_csv\n",
    "create_db_path(src_tables, user_date)\n",
    "create_csv_path(user_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {},
   "outputs": [],
   "source": [
    "source_db.extract_db(src_tables, user_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file extracted.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "extract_csv(user_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 462,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsn_url_dest = \"mysql+pymysql://user:userpass@localhost:3306/mysql_northwind\"\n",
    "dsn_url = \"postgresql+psycopg2://northwind_user:thewindisblowing@localhost:5432/northwind\"\n",
    "engine = sqlalchemy.create_engine(dsn_url)\n",
    "dest_engine = sqlalchemy.create_engine(dsn_url_dest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 463,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error loading data into destination database: (pymysql.err.OperationalError) (3780, \"Referencing column 'supplier_id' and referenced column 'supplier_id' in foreign key constraint 'fk_products_suppliers' are incompatible.\")\n",
      "[SQL: \n",
      "CREATE TABLE suppliers (\n",
      "\tsupplier_id BIGINT, \n",
      "\tcompany_name TEXT, \n",
      "\tcontact_name TEXT, \n",
      "\tcontact_title TEXT, \n",
      "\taddress TEXT, \n",
      "\tcity TEXT, \n",
      "\tregion TEXT, \n",
      "\tpostal_code TEXT, \n",
      "\tcountry TEXT, \n",
      "\tphone TEXT, \n",
      "\tfax TEXT, \n",
      "\thomepage TEXT\n",
      ")\n",
      "\n",
      "]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "Error loading data into destination database: (pymysql.err.OperationalError) (3780, \"Referencing column 'employee_id' and referenced column 'employee_id' in foreign key constraint 'fk_orders_employees' are incompatible.\")\n",
      "[SQL: \n",
      "CREATE TABLE employees (\n",
      "\temployee_id BIGINT, \n",
      "\tlast_name TEXT, \n",
      "\tfirst_name TEXT, \n",
      "\ttitle TEXT, \n",
      "\ttitle_of_courtesy TEXT, \n",
      "\tbirth_date TEXT, \n",
      "\thire_date TEXT, \n",
      "\taddress TEXT, \n",
      "\tcity TEXT, \n",
      "\tregion TEXT, \n",
      "\tpostal_code TEXT, \n",
      "\tcountry TEXT, \n",
      "\thome_phone TEXT, \n",
      "\textension BIGINT, \n",
      "\tphoto TEXT, \n",
      "\tnotes TEXT, \n",
      "\treports_to TEXT, \n",
      "\tphoto_path TEXT\n",
      ")\n",
      "\n",
      "]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "Error loading data into destination database: (pymysql.err.OperationalError) (3780, \"Referencing column 'ship_via' and referenced column 'shipper_id' in foreign key constraint 'fk_orders_shippers' are incompatible.\")\n",
      "[SQL: \n",
      "CREATE TABLE shippers (\n",
      "\tshipper_id BIGINT, \n",
      "\tcompany_name TEXT, \n",
      "\tphone TEXT\n",
      ")\n",
      "\n",
      "]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "Error loading data into destination database: (pymysql.err.OperationalError) (3780, \"Referencing column 'category_id' and referenced column 'category_id' in foreign key constraint 'fk_products_categories' are incompatible.\")\n",
      "[SQL: \n",
      "CREATE TABLE categories (\n",
      "\tcategory_id BIGINT, \n",
      "\tcategory_name TEXT, \n",
      "\tdescription TEXT, \n",
      "\tpicture TEXT\n",
      ")\n",
      "\n",
      "]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "Table employee_territories loaded into destination database.\n",
      "Table region loaded into destination database.\n",
      "Table customer_demographics loaded into destination database.\n",
      "Table us_states loaded into destination database.\n",
      "Error loading data into destination database: 'TABLENAME'\n",
      "Table territories loaded into destination database.\n",
      "Table customer_customer_demo loaded into destination database.\n",
      "Error loading data into destination database: (pymysql.err.OperationalError) (1822, \"Failed to add the foreign key constraint. Missing index for constraint 'fk_orders_customers' in the referenced table 'customers'\")\n",
      "[SQL: \n",
      "CREATE TABLE customers (\n",
      "\tcustomer_id TEXT, \n",
      "\tcompany_name TEXT, \n",
      "\tcontact_name TEXT, \n",
      "\tcontact_title TEXT, \n",
      "\taddress TEXT, \n",
      "\tcity TEXT, \n",
      "\tregion TEXT, \n",
      "\tpostal_code TEXT, \n",
      "\tcountry TEXT, \n",
      "\tphone TEXT, \n",
      "\tfax TEXT\n",
      ")\n",
      "\n",
      "]\n",
      "(Background on this error at: https://sqlalche.me/e/20/e3q8)\n",
      "Error loading data into destination database: 'TABLENAME'\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for table in src_tables:\n",
    "    source = \"postgres\"\n",
    "    success = dest_db.insert_into_db(source, table, user_date)\n",
    "    if success:\n",
    "        print(f\"Table {table} loaded into destination database.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 407,
   "metadata": {},
   "outputs": [],
   "source": [
    "with dest_engine.connect() as connection:\n",
    "    result = connection.execute(text(\"SELECT * FROM region;\"))\n",
    "    for row in result:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scripts.constants import sql_PG_TABLE_NAMES_QUERY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = source_db.get_table_names(sql_PG_TABLE_NAMES_QUERY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "09d4755c393b314f26e68a7d2021da1a34c1a7623ed395e1711305ba626aab55"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
